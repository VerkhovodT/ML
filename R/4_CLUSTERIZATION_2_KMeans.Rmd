---
title: "K-Means"
output:
  word_document: default
  html_notebook: default
  html_document: default
---

# Download the data
```{r}
set.seed(123)
f <- read.csv('bank.csv', header = TRUE, encoding = 'UNICOD')
head(f)
```

## Factors as numeric
```{r}
f <- f[,-1] #exclude ID column
f$sex <- as.numeric(as.factor(f$sex))-1
f$married <- as.numeric(as.factor(f$married))-1
f$car <- as.numeric(as.factor(f$car))-1
f$mortgage <- as.numeric(as.factor(f$mortgage))-1
f$delays <- as.numeric(as.factor(f$delays))-1
head (f)
```

### NbCLust
```{r}
library(factoextra)
library(NbClust)

res.nbclust <- NbClust(f, distance = "euclidean",
                  min.nc = 2, max.nc = 10, 
                  method = "complete", index ="all")
fviz_nbclust(res.nbclust) + theme_minimal() + ggtitle("NbClust's optimal number of clusters")

# Elbow method
# The sum of squares at each number of clusters is calculated and graphed, and the user looks for a change of slope from steep to shallow (an elbow) to determine the optimal number of clusters.
fviz_nbclust(f, kmeans, method = "wss") +
    geom_vline(xintercept = 3, linetype = 2)+
  labs(subtitle = "Elbow method")

# Silhouette method
# The optimal number of clusters k is the one that maximize the average silhouette over a range of possible values for k.
fviz_nbclust(f, kmeans, method = "silhouette")+
  labs(subtitle = "Silhouette method")

# Gap statistic
# The gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic. This means that the clustering structure is far away from the random uniform distribution of points.
fviz_nbclust(f, kmeans, nstart = 25,  method = "gap_stat", nboot = 50)+
  labs(subtitle = "Gap statistic method")
```

# Fitting K-Means to the dataset
```{r}
set.seed(29)
model_km = kmeans(f, 3)
#cluster cores
y_km = model_km$cluster
aggregate(f,by=list(y_km),FUN=mean)
```

# Visualising the clusters
```{r}
library(cluster)
clusplot(f,
         y_km,
         lines = 0,
         shade = TRUE,
         color = TRUE,
         labels= 0,
         plotchar = FALSE,
         span = TRUE,
         main = paste('Clusters of customers'),
         xlab = 'Age',
         ylab = 'Income')
```

# Comparing to HC
```{r}
library(clusteval)
cluster_similarity(y_hc,y_km)
```